## BSD 3-Clause License
##
## Copyright (c) 2021, Andrej Orsula
## All rights reserved.

## Redistribution and use in source and binary forms, with or without
## modification, are permitted provided that the following conditions are met:

## 1. Redistributions of source code must retain the above copyright notice, this
##   list of conditions and the following disclaimer.
##
## 2. Redistributions in binary form must reproduce the above copyright notice,
##   this list of conditions and the following disclaimer in the documentation
##   and/or other materials provided with the distribution.
##
## 3. Neither the name of the copyright holder nor the names of its
##   contributors may be used to endorse or promote products derived from
##   this software without specific prior written permission.
##
## THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
## AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
## IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
## DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
## FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
## DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
## SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
## CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
## OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
## OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.



# Reach task - hyperparameters are not tuned (but agent should learn regardless)
# TODO: Autotune Reach task hyperparameters for T3D
Reach-Gazebo-v0:
  policy: "MlpPolicy"
  policy_kwargs:
    n_critics: 2
    net_arch: [128, 64]
  env_wrapper:
    - drl_grasping.envs.randomizers.ManipulationGazeboEnvRandomizer:
        robot_random_joint_positions: True
        robot_random_joint_positions_std: 0.1
  n_timesteps: 50000
  buffer_size: 25000
  learning_starts: 0
  batch_size: 32
  learning_rate: lin_0.0003
  gamma: 0.95
  tau: 0.01
  train_freq: 1
  gradient_steps: 1
  target_policy_noise: 0.25
  target_noise_clip: 0.5
  noise_type: "normal"
  noise_std: 0.025
  optimize_memory_usage: True

Reach-ColorImage-Gazebo-v0:
  policy: "CnnPolicy"
  policy_kwargs:
    n_critics: 2
    net_arch: [128, 128]
  env_wrapper:
    - drl_grasping.envs.randomizers.ManipulationGazeboEnvRandomizer:
        robot_random_joint_positions: True
        robot_random_joint_positions_std: 0.1
        camera_pose_rollouts_num: 1
        camera_noise_mean: 0
        camera_noise_stddev: 0.001
  n_timesteps: 50000
  buffer_size: 25000
  learning_starts: 0
  batch_size: 32
  learning_rate: lin_0.0003
  gamma: 0.95
  tau: 0.01
  train_freq: 1
  gradient_steps: 1
  target_policy_noise: 0.25
  target_noise_clip: 0.5
  noise_type: "normal"
  noise_std: 0.025
  optimize_memory_usage: True

Reach-Octree-Gazebo-v0:
  policy: "OctreeCnnPolicy"
  policy_kwargs:
    features_extractor_kwargs:
      depth: 4
      full_depth: 2
      channels_in: 4
      channel_multiplier: 8
      full_depth_conv1d: True
      full_depth_channels: 2
      features_dim: 64
      aux_obs_dim: 0
      fast_conv: True
      batch_normalization: False
      bn_eps: 0.00001
      bn_momentum: 0.01
    n_critics: 2
    net_arch: [128, 128]
    separate_networks_for_stacks: False
    share_features_extractor: True
  env_wrapper:
    - drl_grasping.envs.randomizers.ManipulationGazeboEnvRandomizer:
        robot_random_joint_positions: True
        robot_random_joint_positions_std: 0.1
        camera_pose_rollouts_num: 1
        camera_noise_mean: 0
        camera_noise_stddev: 0.001
  n_timesteps: 50000
  buffer_size: 25000
  learning_starts: 0
  batch_size: 32
  learning_rate: lin_0.0003
  gamma: 0.95
  tau: 0.01
  train_freq: 1
  gradient_steps: 1
  target_policy_noise: 0.25
  target_noise_clip: 0.5
  noise_type: "normal"
  noise_std: 0.025
  optimize_memory_usage: True

Reach-OctreeWithColor-Gazebo-v0:
  policy: "OctreeCnnPolicy"
  policy_kwargs:
    features_extractor_kwargs:
      depth: 4
      full_depth: 2
      channels_in: 7
      channel_multiplier: 8
      full_depth_conv1d: True
      full_depth_channels: 2
      features_dim: 64
      aux_obs_dim: 0
      fast_conv: True
      batch_normalization: False
      bn_eps: 0.00001
      bn_momentum: 0.01
    n_critics: 2
    net_arch: [128, 128]
    separate_networks_for_stacks: False
    share_features_extractor: True
  env_wrapper:
    - drl_grasping.envs.randomizers.ManipulationGazeboEnvRandomizer:
        robot_random_joint_positions: True
        robot_random_joint_positions_std: 0.1
        camera_pose_rollouts_num: 1
        camera_noise_mean: 0
        camera_noise_stddev: 0.001
  n_timesteps: 50000
  buffer_size: 25000
  learning_starts: 0
  batch_size: 32
  learning_rate: lin_0.0003
  gamma: 0.95
  tau: 0.01
  train_freq: 1
  gradient_steps: 1
  target_policy_noise: 0.25
  target_noise_clip: 0.5
  noise_type: "normal"
  noise_std: 0.025
  optimize_memory_usage: True

# Grasp task - hyperparameters are not tuned (agent might not learn anything)
# TODO: Autotune Grasp task hyperparameters for TQC
Grasp-Octree-Gazebo-v0:
  policy: "OctreeCnnPolicy"
  policy_kwargs:
    features_extractor_kwargs:
      depth: 4
      full_depth: 2
      channels_in: 4
      channel_multiplier: 32
      full_depth_conv1d: True
      full_depth_channels: 16
      features_dim: 160
      aux_obs_dim: 10
      fast_conv: True
      batch_normalization: False
      bn_eps: 0.00001
      bn_momentum: 0.01
    n_critics: 2
    net_arch: [512, 512]
    separate_networks_for_stacks: True
    share_features_extractor: True
  env_wrapper:
    - drl_grasping.envs.randomizers.ManipulationGazeboEnvRandomizer:
        robot_random_joint_positions: True
        robot_random_joint_positions_std: 0.1
        camera_pose_rollouts_num: 1
        camera_noise_mean: 0
        camera_noise_stddev: 0.001
        ground_model_rollouts_num: 0
        object_random_pose: True
        object_random_use_mesh_models: True
        object_models_rollouts_num: 1
        object_random_model_count: 4
  n_timesteps: 500000
  buffer_size: 40000
  learning_starts: 0
  batch_size: 32
  learning_rate: lin_0.00015
  gamma: 0.999
  tau: 0.00005
  train_freq: [1, "episode"]
  gradient_steps: 100
  target_policy_noise: 0.25
  target_noise_clip: 0.5
  noise_type: "normal"
  noise_std: 0.025
  optimize_memory_usage: True

Grasp-OctreeWithColor-Gazebo-v0:
  policy: "OctreeCnnPolicy"
  policy_kwargs:
    features_extractor_kwargs:
      depth: 4
      full_depth: 2
      channels_in: 7
      channel_multiplier: 32
      full_depth_conv1d: True
      full_depth_channels: 16
      features_dim: 160
      aux_obs_dim: 10
      fast_conv: True
      batch_normalization: False
      bn_eps: 0.00001
      bn_momentum: 0.01
    n_critics: 2
    net_arch: [512, 512]
    separate_networks_for_stacks: True
    share_features_extractor: True
  env_wrapper:
    - drl_grasping.envs.randomizers.ManipulationGazeboEnvRandomizer:
        robot_random_joint_positions: True
        robot_random_joint_positions_std: 0.1
        camera_pose_rollouts_num: 1
        camera_noise_mean: 0
        camera_noise_stddev: 0.001
        ground_model_rollouts_num: 1
        object_random_pose: True
        object_random_use_mesh_models: True
        object_models_rollouts_num: 1
        object_random_model_count: 4
  n_timesteps: 500000
  buffer_size: 40000
  learning_starts: 0
  batch_size: 32
  learning_rate: lin_0.00015
  gamma: 0.999
  tau: 0.00005
  train_freq: [1, "episode"]
  gradient_steps: 100
  target_policy_noise: 0.25
  target_noise_clip: 0.5
  noise_type: "normal"
  noise_std: 0.025
  optimize_memory_usage: True



IK-Gazebo-v0:
  policy: "MlpPolicy"
  policy_kwargs:
    n_critics: 2
    net_arch: [128, 64]
  env_wrapper:
    - drl_grasping.envs.randomizers.ManipulationGazeboEnvRandomizer:
        robot_random_joint_positions: False
        invisible_world_bottom_collision_plane: False
        visualise_workspace: False
        visualise_spawn_volume: True
  n_timesteps: 50000
  buffer_size: 25000
  learning_starts: 0
  batch_size: 32
  learning_rate: lin_0.0003
  gamma: 0.95
  tau: 0.01
  train_freq: 1
  gradient_steps: 1
  target_policy_noise: 0.25
  target_noise_clip: 0.5
  noise_type: "normal"
  noise_std: 0.025
  optimize_memory_usage: True

   
